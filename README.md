# Apache-spark
Analyse et visualisation de données à grande échelle sur des données semi-structurées

![architecture](img.png)


## Apache SPARK utilisant Jupyter dans LINUX : Installation et configuration
https://medium.com/python-in-plain-english/apache-spark-using-jupyter-in-linux-installation-and-setup-b2cacc6c7701

Grâce au Big Data, à un calcul amélioré et distribué, au traitement du Big Data et à des cadres d'analyse open source tels que Spark, nous pouvons effectuer des analyses de journaux évolutives sur potentiellement des millions et des milliards de messages de journal par jour. Le but de ce didacticiel axé sur les études de cas est d'adopter une approche pratique pour montrer comment nous pouvons tirer parti de Spark pour effectuer des analyses de journaux à grande échelle sur des données de journal semi-structurées. Si vous êtes intéressé par le SQL évolutif avec Spark, n'hésitez pas à découvrir SQL à grande échelle avec Spark .
principaux sujets suivants dans cet article.
### Objectif principal - Analyse des journaux de la NASA
### Configurer les dépendances
### Chargement et affichage de l'ensemble de données du journal de la NASA
### Data Wrangling
### Analyse des données sur nos journaux Web
